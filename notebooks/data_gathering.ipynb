{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_list = []\n",
    "for i in range(2008, 2024, 1):\n",
    "    time.sleep(0.5)\n",
    "    print(i)\n",
    "    if i in range(2010, 2016):\n",
    "        tables_list.append(pd.read_html(f\"https://en.wikipedia.org/wiki/{i}_FIFA_Ballon_d'Or\"))\n",
    "    elif i == 2020:\n",
    "        continue\n",
    "    elif i == 2016:\n",
    "        tables_list.append(pd.read_html(\"https://en.wikipedia.org/wiki/2016_Ballon_d%27Or\"))\n",
    "    else:\n",
    "        tables_list.append(pd.read_html(f\"https://en.wikipedia.org/wiki/{i}_Ballon_d'Or\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_list[0][2]['year'] = [2008 for i in range(len(tables_list[0][2]))]\n",
    "tables_list[0] = tables_list[0][2]\n",
    "\n",
    "tables_list[1][2]['year'] = [2009 for i in range(len(tables_list[1][2]))]\n",
    "tables_list[1] = tables_list[1][2]\n",
    "\n",
    "tables_list[2] = pd.concat([tables_list[2][2], tables_list[2][3]], ignore_index=True)\n",
    "tables_list[2]['year'] = [2010 for i in range(len(tables_list[2]))]\n",
    "\n",
    "table = pd.concat([tables_list[3][2], tables_list[3][3]], ignore_index=True)\n",
    "playas = []\n",
    "for i in range(len(table)):\n",
    "    if i in [0,1,2]:\n",
    "        playas.append(table['Player[2]'][i])\n",
    "    else:\n",
    "        playas.append(table['Player[3]'][i])\n",
    "table['player'] = playas\n",
    "table['year'] = [2011 for i in range(len(table))]\n",
    "tables_list[3] = table\n",
    "\n",
    "n = 4\n",
    "table = pd.concat([tables_list[n][2], tables_list[n][3]], ignore_index=True)\n",
    "table['year'] = [2012 for i in range(len(table))]\n",
    "tables_list[n] = table\n",
    "\n",
    "n = 5\n",
    "table = pd.concat([tables_list[n][2], tables_list[n][3]], ignore_index=True)\n",
    "table['year'] = [2013 for i in range(len(table))]\n",
    "tables_list[n] = table\n",
    "\n",
    "n = 6\n",
    "table = pd.concat([tables_list[n][2], tables_list[n][3]], ignore_index=True)\n",
    "table['year'] = [2014 for i in range(len(table))]\n",
    "tables_list[n] = table\n",
    "\n",
    "n = 7\n",
    "table = pd.concat([tables_list[n][2], tables_list[n][3]], ignore_index=True)\n",
    "table['year'] = [2015 for i in range(len(table))]\n",
    "tables_list[n] = table\n",
    "\n",
    "tables_list[8][2]['year'] = [2016 for i in range(len(tables_list[8][2]))]\n",
    "tables_list[8] = tables_list[8][2]\n",
    "\n",
    "n=9\n",
    "table = tables_list[n][2]\n",
    "# table = pd.concat([tables_list[n][2], tables_list[n][3]], ignore_index=True)\n",
    "table['year'] = [2017 for i in range(len(table))]\n",
    "tables_list[n] = table\n",
    "\n",
    "tables_list[10][2]['year'] = [2018 for i in range(len(tables_list[10][2]))]\n",
    "tables_list[10] = tables_list[10][2]\n",
    "\n",
    "tables_list[11] = pd.read_html(\"https://en.wikipedia.org/wiki/2019_Ballon_d'Or\")\n",
    "tables_list[11][2]['year'] = [2019 for i in range(len(tables_list[11][2]))]\n",
    "tables_list[11] = tables_list[11][2]\n",
    "\n",
    "tables_list[12][2]['year'] = [2021 for i in range(len(tables_list[12][2]))]\n",
    "tables_list[12] = tables_list[12][2]\n",
    "\n",
    "tables_list[13][2]['year'] = [2022 for i in range(len(tables_list[13][2]))]\n",
    "tables_list[13] = tables_list[13][2]\n",
    "\n",
    "# tables_list.append(pd.read_html(\"https://en.wikipedia.org/wiki/2023_Ballon_d'Or\"))\n",
    "tables_list[14][2]['year'] = [2023 for i in range(len(tables_list[14][2]))]\n",
    "tables_list[14] = tables_list[14][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table = pd.concat(tables_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table.columns = [x.lower() for x in big_table.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(big_table.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "# big_table.columns = ['rank', 'player0', 'nationality', 'club(s)', 'points', 'year', 'percent', 'player1', 'player2', 'player3', 'player4', 'votes', 'parser0', 'parser1', 'position', 'club']\n",
    "big_table.columns = ['rank', 'player0', 'nationality', 'club(s)', 'points', 'year', 'percent', 'player1', 'player2', 'player3', 'player4', 'votes', 'position', 'club']\n",
    "big_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_player_list = []\n",
    "count_before = big_table.shape[0]\n",
    "row_remove_idx = []\n",
    "for idx, row in big_table.iterrows():\n",
    "    # assigning players\n",
    "    p0 = row['player0']\n",
    "    p1 = row['player1']\n",
    "    p2 = row['player2']\n",
    "    p3 = row['player3']\n",
    "    p4 = row['player4']\n",
    "\n",
    "    non_nans = []\n",
    "    nan_count = 0\n",
    "    for i in [p0, p1, p2, p3, p4]:\n",
    "        if not isinstance(i, str) and math.isnan(i):\n",
    "            nan_count += 1\n",
    "        else:\n",
    "            non_nans.append(i)\n",
    "    \n",
    "    # only one non-nan value, so we can assume correctness\n",
    "    if nan_count == 4 and len(non_nans) == 1:\n",
    "        new_player_list.append(non_nans[0])\n",
    "    \n",
    "    # if multiple non-nan values but they are the same, we can assume correctness\n",
    "    elif len(set(non_nans)) == 1:\n",
    "        new_player_list.append(non_nans[0])\n",
    "    \n",
    "    # luckily there are never multiple players in same row\n",
    "    elif len(set(non_nans)) >= 1:\n",
    "        print('Multiple players in same row!?')\n",
    "\n",
    "    # no player name in row, this occurs 5 times\n",
    "    elif nan_count == 5:\n",
    "        # uncommenting print and looking via manual inspection shows no useful information in rows, so we can skip them\n",
    "        # print(row)\n",
    "        row_remove_idx.append(idx)\n",
    "\n",
    "count_after = len(new_player_list)\n",
    "print(f'Lost {count_before-count_after} rows')\n",
    "\n",
    "big_table.drop(row_remove_idx, inplace=True)\n",
    "\n",
    "# adding new column\n",
    "big_table['player'] = new_player_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing old columns and crazy columns\n",
    "big_table = big_table[['year', 'player', 'rank', 'points', 'votes', 'percent', 'position', 'club', 'club(s)', 'nationality']].reset_index(drop=True)\n",
    "big_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many nans in points and votes especially makes me question their usability\n",
    "print(big_table.shape[0])\n",
    "print(big_table['points'].isna().sum())\n",
    "print(big_table['votes'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hopefully columns can just be mergeable and nans will disappear\n",
    "print(big_table.shape[0])\n",
    "print(big_table['club'].isna().sum())\n",
    "print(big_table['club(s)'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_nan_count = 0\n",
    "both_nan_count = 0\n",
    "for idx, row in big_table.iterrows():\n",
    "    club = row['club']\n",
    "    clubs = row['club(s)']\n",
    "\n",
    "    if club == clubs:\n",
    "        print('same')\n",
    "\n",
    "    elif isinstance(clubs, str) and not isinstance(club, str) and math.isnan(club):\n",
    "        # print(f'club is nan, club(s) is {clubs}')\n",
    "        one_nan_count += 1\n",
    "\n",
    "    elif isinstance(club, str) and not isinstance(clubs, str) and math.isnan(clubs):\n",
    "        # print(f'club(s) is nan, club is {club}')\n",
    "        one_nan_count += 1\n",
    "\n",
    "    elif not isinstance(club, str) and math.isnan(club) and not isinstance(clubs, str) and math.isnan(clubs):\n",
    "        # print('both are nan')\n",
    "        both_nan_count += 1\n",
    "    \n",
    "print(one_nan_count)\n",
    "print(both_nan_count)\n",
    "\n",
    "# only one_nan_counts means we can merge the columns easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing old clubs and adding new club column with no nans\n",
    "new_club = []\n",
    "for idx, row in big_table.iterrows():\n",
    "    club = row['club']\n",
    "    clubs = row['club(s)']\n",
    "\n",
    "    if isinstance(club, str):\n",
    "        new_club.append(club)\n",
    "    else:\n",
    "        new_club.append(clubs)\n",
    "\n",
    "big_table.drop(['club', 'club(s)'], axis=1, inplace=True)\n",
    "big_table['club'] = new_club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing ranks that show as 1st etc. with just numbers\n",
    "def replace_st_nd_rd_th(rank):\n",
    "    if isinstance(rank, str):\n",
    "        rank = rank.replace('st', '')\n",
    "        rank = rank.replace('nd', '')\n",
    "        rank = rank.replace('rd', '')\n",
    "        rank = rank.replace('th', '')\n",
    "    \n",
    "    return int(rank)\n",
    "\n",
    "big_table['rank'] = big_table['rank'].apply(replace_st_nd_rd_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(big_table.shape[0])\n",
    "print(big_table['year'].isna().sum())\n",
    "print(big_table['player'].isna().sum())\n",
    "print(big_table['rank'].isna().sum())\n",
    "print(big_table['points'].isna().sum())\n",
    "print(big_table['votes'].isna().sum())\n",
    "print(big_table['position'].isna().sum())\n",
    "print(big_table['percent'].isna().sum())\n",
    "print(big_table['nationality'].isna().sum())\n",
    "print(big_table['club'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in nationalities by building dict of players and filling in after\n",
    "# after googling there are actually some big players who changed nationality so it might be worth not getting rid of nans this way but getting them from another data source\n",
    "\n",
    "nans_before = big_table['nationality'].isna().sum()\n",
    "\n",
    "# build dict\n",
    "player_nats = dict()\n",
    "for idx, row in big_table.iterrows():\n",
    "    player = row['player']\n",
    "    nat = row['nationality']\n",
    "\n",
    "    if player not in player_nats.keys():\n",
    "        if isinstance(nat, str):\n",
    "            player_nats[player] = nat\n",
    "\n",
    "# make list corresponding to df\n",
    "new_nats = []\n",
    "for idx, row in big_table.iterrows():\n",
    "    player = row['player']\n",
    "    nat = row['nationality']\n",
    "\n",
    "    if player in player_nats.keys():\n",
    "        new_nats.append(player_nats[player])\n",
    "    else:\n",
    "        new_nats.append(np.nan)\n",
    "\n",
    "# remove old column and add new\n",
    "big_table.drop('nationality', axis=1, inplace=True)\n",
    "big_table['nationality'] = new_nats\n",
    "\n",
    "nans_after = big_table['nationality'].isna().sum()\n",
    "print('nans before:', nans_before)\n",
    "print('nans after:', nans_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(big_table.shape[0])\n",
    "print(big_table['year'].isna().sum())\n",
    "print(big_table['player'].isna().sum())\n",
    "print(big_table['rank'].isna().sum())\n",
    "print(big_table['points'].isna().sum())\n",
    "print(big_table['votes'].isna().sum())\n",
    "print(big_table['position'].isna().sum())\n",
    "print(big_table['percent'].isna().sum())\n",
    "print(big_table['nationality'].isna().sum())\n",
    "print(big_table['club'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for differences in csv and this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('../data/BallonDOr.csv')\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csv.shape[0])\n",
    "print(csv['Year'].isna().sum())\n",
    "print(csv['Rank'].isna().sum())\n",
    "print(csv['Player'].isna().sum())\n",
    "print(csv['Club'].isna().sum())\n",
    "print(csv['Nationality'].isna().sum())\n",
    "print(csv['Points'].isna().sum())\n",
    "print(csv['P1'].isna().sum())\n",
    "print(csv['P2'].isna().sum())\n",
    "print(csv['P3'].isna().sum())\n",
    "print(csv['P4'].isna().sum())\n",
    "print(csv['P5'].isna().sum())\n",
    "print(csv['Votes'].isna().sum())\n",
    "print(csv['RankPts'].isna().sum())\n",
    "print(csv['Share'].isna().sum())\n",
    "print(csv['Percent'].isna().sum())\n",
    "print(csv['Voted'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for differences in data\n",
    "\n",
    "# difference in number of records from 2008 to 2023\n",
    "years_to_check = big_table.year.unique()\n",
    "csv_years = csv[csv['Year'].isin(years_to_check)]\n",
    "print(csv_years.shape[0])\n",
    "print(big_table.shape[0])\n",
    "\n",
    "# difference in rankings and player related data\n",
    "for year in big_table.year.unique():\n",
    "    print(year)\n",
    "    big_table_ranks = big_table[big_table['year'] == year]['rank'].values\n",
    "    csv_ranks = csv[csv['Year'] == 2008]['Rank'].values\n",
    "\n",
    "    if len(big_table_ranks) > len(csv_ranks):\n",
    "        if np.array_equal(big_table_ranks[:len(csv_ranks)], csv_ranks):\n",
    "            print('More data in big table otherwise both the same!')\n",
    "        else:\n",
    "            print('More data in big table but mismatch in data!')\n",
    "        \n",
    "    elif len(big_table_ranks) < len(csv_ranks):\n",
    "        if np.array_equal(big_table_ranks, csv_ranks[:len(big_table_ranks)]):\n",
    "            print('More data in csv ranks otherwise both the same!')\n",
    "        else:\n",
    "            print('More data in csv ranks but mismatch in data!')\n",
    "    \n",
    "    else:\n",
    "        if np.array_equal(big_table_ranks, csv_ranks):\n",
    "            print('Same lengths and data matches!')\n",
    "        else:\n",
    "            print('Same lengths but data mimatch!')\n",
    "\n",
    "    print(big_table_ranks)\n",
    "    print(csv_ranks)\n",
    "\n",
    "    # check if first 5 winners are the same\n",
    "    print(big_table[big_table['year'] == year]['player'][:5])\n",
    "    print(csv[csv['Year'] == year]['Player'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding 2019-2021-2022-2023 years from big_table to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_relevant = big_table[big_table['year'].isin([2019, 2021, 2022, 2023])]\n",
    "\n",
    "share = []\n",
    "for year in [2019, 2021, 2022, 2023]:\n",
    "    total_points = big_table_relevant[big_table_relevant['year']==year]['points'].sum()\n",
    "    \n",
    "    for idx, row in big_table_relevant[big_table_relevant['year']==year].iterrows():\n",
    "        share.append(round(row['points']/total_points, 4))\n",
    "\n",
    "big_table_relevant['share'] = share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepping for adding by removing unwanted columns and adding new ones\n",
    "big_table_relevant.drop('position', axis=1, inplace=True)\n",
    "\n",
    "big_table_relevant.columns = ['Year', 'Player', 'Rank', 'Points', 'Votes', 'Percent', 'Club', 'Nationality', 'Share']\n",
    "\n",
    "big_table_relevant['P1'] = [np.nan] * big_table_relevant.shape[0]\n",
    "big_table_relevant['P2'] = [np.nan] * big_table_relevant.shape[0]\n",
    "big_table_relevant['P3'] = [np.nan] * big_table_relevant.shape[0]\n",
    "big_table_relevant['P4'] = [np.nan] * big_table_relevant.shape[0]\n",
    "big_table_relevant['P5'] = [np.nan] * big_table_relevant.shape[0]\n",
    "big_table_relevant['RankPts'] = [np.nan] * big_table_relevant.shape[0]\n",
    "big_table_relevant['Percent'] = [np.nan] * big_table_relevant.shape[0]\n",
    "big_table_relevant['Voted'] = [np.nan] * big_table_relevant.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_relevant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([csv, big_table_relevant])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape[0])\n",
    "print(df['Year'].isna().sum())\n",
    "print(df['Rank'].isna().sum())\n",
    "print(df['Player'].isna().sum())\n",
    "print(df['Club'].isna().sum())\n",
    "print(df['Nationality'].isna().sum())\n",
    "print(df['Points'].isna().sum())\n",
    "print(df['P1'].isna().sum())\n",
    "print(df['P2'].isna().sum())\n",
    "print(df['P3'].isna().sum())\n",
    "print(df['P4'].isna().sum())\n",
    "print(df['P5'].isna().sum())\n",
    "print(df['Votes'].isna().sum())\n",
    "print(df['RankPts'].isna().sum())\n",
    "print(df['Share'].isna().sum())\n",
    "print(df['Percent'].isna().sum())\n",
    "print(df['Voted'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/BallonDOr_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "outplayed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
